{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lab 1. Why fine-tune\n",
        "In this lab, you'll get to learn why you should fine-tune, what\n",
        "fine-tuning really even is, compare it to\n",
        "prompt engineering, and go through a lab where you get to\n",
        "compare a fine-tuned model to a non-fine-tuned model."
      ],
      "metadata": {
        "id": "1Tjik4w9cuH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lamini https://www.lamini.ai is a Python library on top of Pytorch and Hugging Face\n",
        "you can fine-tune models with just a few lines of code"
      ],
      "metadata": {
        "id": "0_PD27umoiVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lamini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfP9zbI_KcaI",
        "outputId": "02bb829f-61e3-4041-9bec-4515f3c78d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lamini\n",
            "  Downloading lamini-2.0.6-76-py3-none-any.whl (24 kB)\n",
            "Collecting lamini-configuration[yaml] (from lamini)\n",
            "  Downloading lamini_configuration-0.8.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lamini) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lamini) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lamini) (1.23.5)\n",
            "Collecting jsonlines (from lamini)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lamini) (1.5.3)\n",
            "Collecting azure-storage-blob (from lamini)\n",
            "  Downloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lamini) (1.2.2)\n",
            "Collecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob->lamini)\n",
            "  Downloading azure_core-1.29.7-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.9/192.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (41.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (4.5.0)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob->lamini)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lamini) (23.2.0)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from lamini-configuration[yaml]->lamini) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2023.11.17)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (3.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob->lamini) (1.16.0)\n",
            "Collecting typing-extensions>=4.3.0 (from azure-storage-blob->lamini)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob->lamini) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->lamini) (2.21)\n",
            "Installing collected packages: typing-extensions, lamini-configuration, jsonlines, isodate, azure-core, azure-storage-blob, lamini\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed azure-core-1.29.7 azure-storage-blob-12.19.0 isodate-0.6.1 jsonlines-4.0.0 lamini-2.0.6 lamini-configuration-0.8.3 typing-extensions-4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sign-in to lamini account here https://app.lamini.ai to get you your own api-key."
      ],
      "metadata": {
        "id": "paDE8UMepfEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lamini\n",
        "lamini.api_key = \"795e723060721cfb7677cfbe85eaa1f01dd18c42\"\n",
        "#lamini.api_key = \"your-api-key\"\n"
      ],
      "metadata": {
        "id": "sXxlYTQJKYmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try fine-tuned Llama2 model"
      ],
      "metadata": {
        "id": "YM8Be1sSpnGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = lamini.Lamini(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "print(llm.generate(\"How are you?\"))"
      ],
      "metadata": {
        "id": "LO3IKoNdK6tu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db72e76d-50e8-4e0e-bede-8c136f01b23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I hope you are doing well.\n",
            "I am writing to you today to ask for your help. As you may know, I am a big fan of your work and I have been following your career for many years. I must say, you are an inspiration to me and many others.\n",
            "\n",
            "I am reaching out to you because I am in a bit of a difficult situation and I was hoping you could offer me some advice. You see, I have been struggling with [insert problem here] and I am not sure how to handle it. I have tried [insert solutions here] but they have not worked for me. I was hoping you could share some of your wisdom and experience with me.\n",
            "\n",
            "I know that you are a very busy person, but I would be forever grateful if you could take the time to respond to my message. I promise to keep your advice confidential and to use it to help me overcome my problem.\n",
            "\n",
            "Thank you in advance for your time and consideration. I look forward to hearing from you soon.\n",
            "\n",
            "Sincerely,\n",
            "[Your Name]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare finetuned vs. non-finetuned models"
      ],
      "metadata": {
        "id": "Er8jjnhRK7Fp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import BasicModeRuner to run open source models on GPUs. These are hosted open-source models on GPUs to\n",
        "run them really efficiently."
      ],
      "metadata": {
        "id": "U9NhfgbuLKEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama import BasicModelRunner"
      ],
      "metadata": {
        "id": "rXmKHt05LWrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try Non-Finetuned models\n"
      ],
      "metadata": {
        "id": "9IplAkxZLiQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First model you can run here is the LLAMA2 model, which is very popular right now. And this one is not fine-tuned."
      ],
      "metadata": {
        "id": "YvPMRfXuqXkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_finetuned = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")"
      ],
      "metadata": {
        "id": "iBnExffqLs5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_finetuned_output = non_finetuned(\"Tell me how to train my dog to sit\")"
      ],
      "metadata": {
        "id": "oYdnbgsmLvF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(non_finetuned_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMRbDjMrLycT",
        "outputId": "1614cf04-129a-4deb-87a9-c79b254cb2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "Tell me how to train my dog to sit. I have a 10 month old puppy and I want to train him to sit. I have tried the treat method and the verbal command method. I have tried both and he just doesn't seem to get it. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you explore? Try different prompts"
      ],
      "metadata": {
        "id": "o24DAZheMCsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(non_finetuned(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
        "Customer: I didn't get my item\n",
        "Agent: I'm sorry to hear that. Which item was it?\n",
        "Customer: the blanket\n",
        "Agent:\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg66cQkXMQZg",
        "outputId": "0470d74b-6a6a-4fdb-e29f-2e585c71ab25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I'm sorry to hear that. I'll look into it.\n",
            "Customer: I'm not sure if I got the right blanket.\n",
            "Agent: I'm sorry to hear that. I'll look into it.\n",
            "Customer: I'm not sure if I got the right blanket. I'm not sure if I got the right blanket.\n",
            "Agent: I'm sorry to hear that. I'll look into it. I'll look into it.\n",
            "Customer: I'm not sure if I got the right blanket. I'm not sure if I got the right blanket. I'm not sure if I got the right blanket.\n",
            "Agent: I'm sorry to hear that. I'll look into it. I'll look into it. I'll look into it.\n",
            "Customer: I'm not sure if I got the right blanket. I'm not sure if I got the right blanket. I'm not sure if I got the right blanket. I'm not sure if I got the right blanket. I'm not sure if I got the right blanket. I'm not sure if I got the right blank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare to finetuned models"
      ],
      "metadata": {
        "id": "RDMRxdmaMXcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare this to Llama 2 that has been fine-tuned to actually chat."
      ],
      "metadata": {
        "id": "p3pDuH16rLa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")"
      ],
      "metadata": {
        "id": "zq4oLKl7Ma_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_output = finetuned_model(\"Tell me how to train my dog to sit\")"
      ],
      "metadata": {
        "id": "GuB5eSdvMfFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(finetuned_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oph9PLwHMj0s",
        "outputId": "a4725948-6cc9-425b-c8b2-a9d6e2101557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " on command.\n",
            "Training a dog to sit on command is a basic obedience command that can be achieved with patience, consistency, and positive reinforcement. Here's a step-by-step guide on how to train your dog to sit on command:\n",
            "\n",
            "1. Choose a quiet and distraction-free area: Find a quiet area with minimal distractions where your dog can focus on you.\n",
            "2. Have treats ready: Choose your dog's favorite treats and have them ready to use as rewards.\n",
            "3. Stand in front of your dog: Stand in front of your dog and hold a treat close to their nose.\n",
            "4. Move the treat up and back: Slowly move the treat up and back, towards your dog's tail, while saying \"sit\" in a calm and clear voice.\n",
            "5. Dog will sit: As you move the treat, your dog will naturally sit down to follow the treat. The moment their bottom touches the ground, say \"good sit\" and give them the treat.\n",
            "6. Repeat the process: Repeat steps 3-5 several times, so your dog starts to associate the command \"sit\" with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(finetuned_model(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
        "Customer: I didn't get my item\n",
        "Agent: I'm sorry to hear that. Which item was it?\n",
        "Customer: the blanket\n",
        "Agent:\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzb8gbVjMn66",
        "outputId": "88f16335-6cbf-49a1-9dd3-a23cc1875484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I see. Can you please provide me with your order number so I can look into this for you?\n",
            "Customer: I don't have the order number.\n",
            "Agent: Okay, no worries. Can you please tell me the name of the item you didn't receive?\n",
            "Customer: It was a blue blanket.\n",
            "Agent: I see. I'm going to check on the status of your order for you. Can you please hold for just a moment?\n",
            "Customer: Okay, thank you.\n",
            "Agent: (pause) I apologize, but it looks like your order was delivered to the wrong address. Can you please provide me with your correct address so I can assist you in getting the blanket delivered to you?\n",
            "Customer: (sighs) I don't know why this is happening to me. I've been ordering from Amazon for years and never had any problems.\n",
            "Agent: I apologize for any inconvenience this has caused. I'm here to help you resolve the issue as quickly as possible. Can you please provide me with your correct address so I can assist you?\n",
            "Customer: (frustrated) Fine. It's 123 Main St, Apartment \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to put instruction tags. This helps with telling the model, hey,\n",
        "these are my instructions and these are the boundaries."
      ],
      "metadata": {
        "id": "iG9m4ADzrnuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(finetuned_model(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOFHvWCzNzao",
        "outputId": "c84de7d7-b204-4f6a-b851-9d2ff2f27fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Training your dog to sit is a basic obedience command that can be achieved with patience, consistency, and positive reinforcement. Here's a step-by-step guide on how to train your dog to sit:\n",
            "\n",
            "1. Choose a quiet and distraction-free area: Find a quiet area with no distractions where your dog can focus on you.\n",
            "2. Have treats ready: Choose your dog's favorite treats and have them ready to use as rewards.\n",
            "3. Stand in front of your dog: Stand in front of your dog and hold a treat close to their nose.\n",
            "4. Move the treat up and back: Slowly move the treat up and back, towards your dog's tail, while saying \"sit\" in a calm and clear voice.\n",
            "5. Dog will sit: As you move the treat, your dog will naturally sit down to follow the treat. The moment their bottom touches the ground, say \"good sit\" and give them the treat.\n",
            "6. Repeat the process: Repeat steps 3-5 several times, so your dog starts to associate the command \"sit\" with the action of sitting down.\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(finetuned_model(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
        "Customer: I didn't get my item\n",
        "Agent: I'm sorry to hear that. Which item was it?\n",
        "Customer: the blanket\n",
        "Agent:\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi1vKfWXt2bA",
        "outputId": "e9e47239-0b27-4185-be72-9a626c8a629d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I see. Can you please provide me with your order number so I can look into this for you?\n",
            "Customer: I don't have the order number.\n",
            "Agent: Okay, no worries. Can you please tell me the name of the item you didn't receive?\n",
            "Customer: It was a blue blanket.\n",
            "Agent: I see. I'm going to check on the status of your order for you. Can you please hold for just a moment?\n",
            "Customer: Okay, thank you.\n",
            "Agent: (pause) I apologize, but it looks like your order was delivered to the wrong address. Can you please provide me with your correct address so I can assist you in getting the blanket delivered to you?\n",
            "Customer: (sighs) I don't know why this is happening to me. I've been ordering from Amazon for years and never had any problems.\n",
            "Agent: I apologize for any inconvenience this has caused. I'm here to help you resolve the issue as quickly as possible. Can you please provide me with your correct address so I can assist you?\n",
            "Customer: (frustrated) Fine. It's 123 Main St, Apartment \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare to different open source models"
      ],
      "metadata": {
        "id": "BRPIgXMtMtEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "your can try different open source models and compare the output:\n",
        "'Intel/neural-chat-7b-v3-1', 'mistralai/Mistral-7B-Instruct-v0.1'"
      ],
      "metadata": {
        "id": "OCRNnA--tfD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "microsoft = BasicModelRunner(\"microsoft/phi-2\")"
      ],
      "metadata": {
        "id": "MRclpVgKMyOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(microsoft(\"Tell me how to train my dog to sit\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDES6OHkM1bw",
        "outputId": "574c5870-c84c-4036-be64-a384d214c239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\"\n",
            "\n",
            "\"Sure,\" said Sarah. \"First, hold a treat above your dog's head and slowly move it back towards their tail. As they follow the treat with their eyes, their bottom will naturally lower to the ground. Once they are in a sitting position, say'sit' and give them the treat.\"\n",
            "\n",
            "\"That sounds easy enough,\" said John. \"But what if my dog doesn't listen?\"\n",
            "\n",
            "\"Well, you can try using a clicker to mark the behavior you want to reinforce,\" said Sarah. \"Then, give them the treat right away. It's important to be consistent and patient with training.\"\n",
            "\n",
            "\"I see,\" said John. \"Thanks for the advice, Sarah. I'll give it a try.\"\n",
            "\n",
            "As they continued their conversation, Sarah noticed that John was wearing a new pair of shoes.\n",
            "\n",
            "\"Those are nice shoes, John,\" she said. \"Where did you get them?\"\n",
            "\n",
            "\"I got them at the mall,\" said John. \"They were on sale, so I couldn't resist.\"\n",
            "\n",
            "\"I love shopping for shoes,\" said Sarah. \"I have a whole closet full of them. I even have a separate shoe rack just for my heels.\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab2. Instruction-tuning. Data collection"
      ],
      "metadata": {
        "id": "-OIfEYP2OZh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab you'll learn about instruction fine-tuning, a\n",
        "variant of fine-tuning that enabled GPT-3 to turn into\n",
        "chat GPT and give it its chatting powers."
      ],
      "metadata": {
        "id": "IfPXxLsSvJgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAktVzE0Opnm",
        "outputId": "91f82745-cbc4-4f9f-ee6e-3b7c0df630e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setfit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjmD3XCBPLSd",
        "outputId": "51cb3cfc-d7df-4d42-ed86-6f1f7fddf79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting setfit\n",
            "  Downloading setfit-1.0.3-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.3.0 (from setfit)\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers>=2.2.1 (from setfit)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate>=0.3.0 (from setfit)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from setfit) (0.20.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from setfit) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from setfit) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.3.0->setfit)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (3.4.1)\n",
            "Collecting multiprocess (from datasets>=2.3.0->setfit)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (3.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (6.0.1)\n",
            "Collecting responses<0.19 (from evaluate>=0.3.0->setfit)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->setfit) (4.9.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (4.35.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (0.16.0+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers>=2.2.1->setfit)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->setfit) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->setfit) (3.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (2023.11.17)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=2.2.1->setfit) (8.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.3.0->setfit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.3.0->setfit) (2023.3.post1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers>=2.2.1->setfit) (9.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets>=2.3.0->setfit) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=524a63bcadc6d9924d74c8f6478e542da5e1f8b3c24843a568abb31279bdfaf6\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, dill, responses, multiprocess, datasets, sentence-transformers, evaluate, setfit\n",
            "Successfully installed datasets-2.16.1 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 responses-0.18.0 sentence-transformers-2.2.2 sentencepiece-0.1.99 setfit-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import jsonlines\n",
        "\n",
        "from datasets import load_dataset, Dataset\n",
        "from pprint import pprint\n",
        "\n",
        "from llama import BasicModelRunner\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "JJ80k4K4Oh6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load instruction tuned dataset"
      ],
      "metadata": {
        "id": "xq55obOLPfSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "load up instruction tune data set and this is specifying the\n",
        "alpaca data set. Have a look here: https://huggingface.co/datasets/tatsu-lab/alpaca"
      ],
      "metadata": {
        "id": "TTprQPaRzuVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction_tuned_dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True)"
      ],
      "metadata": {
        "id": "C7F52fF0Ob-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = 5\n",
        "print(\"Instruction-tuned dataset:\")\n",
        "top_m = list(itertools.islice(instruction_tuned_dataset, m))\n",
        "for j in top_m:\n",
        "  print(j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUK5T7oIPYY8",
        "outputId": "c67ac96e-27bd-4e45-f3e4-07dd6c81146d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction-tuned dataset:\n",
            "{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}\n",
            "{'instruction': 'What are the three primary colors?', 'input': '', 'output': 'The three primary colors are red, blue, and yellow.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat are the three primary colors?\\n\\n### Response:\\nThe three primary colors are red, blue, and yellow.'}\n",
            "{'instruction': 'Describe the structure of an atom.', 'input': '', 'output': 'An atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe the structure of an atom.\\n\\n### Response:\\nAn atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.'}\n",
            "{'instruction': 'How can we reduce air pollution?', 'input': '', 'output': 'There are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nHow can we reduce air pollution?\\n\\n### Response:\\nThere are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.'}\n",
            "{'instruction': 'Describe a time when you had to make a difficult decision.', 'input': '', 'output': 'I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe a time when you had to make a difficult decision.\\n\\n### Response:\\nI had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two prompt templates"
      ],
      "metadata": {
        "id": "NJt4Jy8JPsfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The authors of the alpaca dataset paper had two prompt templates because\n",
        "they wanted the model to be able to work with two different\n",
        "types of prompts and two different types of tasks\n",
        "essentially. Details are here: https://github.com/tatsu-lab/stanford_alpaca"
      ],
      "metadata": {
        "id": "ZF1_BjOM1PtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_with_input = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Input:\n",
        "{input}\n",
        "\n",
        "### Response:\"\"\"\n",
        "\n",
        "prompt_template_without_input = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Response:\"\"\""
      ],
      "metadata": {
        "id": "_vm9O50NPqXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "add data to prompts"
      ],
      "metadata": {
        "id": "_sV8VYdtP0wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = []\n",
        "for j in top_m:\n",
        "  if not j[\"input\"]:\n",
        "    processed_prompt = prompt_template_without_input.format(instruction=j[\"instruction\"])\n",
        "  else:\n",
        "    processed_prompt = prompt_template_with_input.format(instruction=j[\"instruction\"], input=j[\"input\"])\n",
        "\n",
        "  processed_data.append({\"input\": processed_prompt, \"output\": j[\"output\"]})\n"
      ],
      "metadata": {
        "id": "kgj3UO9IP5Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "save data to jsonl"
      ],
      "metadata": {
        "id": "1qO1nbigP97V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open(f'alpaca_processed.jsonl', 'w') as writer:\n",
        "    writer.write_all(processed_data)"
      ],
      "metadata": {
        "id": "8YVmjw8DQB8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare non-instruction-tuned vs. instruction-tuned models"
      ],
      "metadata": {
        "id": "KuiSz7EbQGTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path_hf = \"lamini/alpaca\"\n",
        "dataset_hf = load_dataset(dataset_path_hf)\n",
        "print(dataset_hf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNN3yBQ7QDvL",
        "outputId": "8d56e222-f58a-4267-d4b2-c537546aa234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input', 'output'],\n",
            "        num_rows: 52002\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_instruct_model = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")\n",
        "non_instruct_output = non_instruct_model(\"Tell me how to train my dog to sit\")\n",
        "print(\"Not instruction-tuned output (Llama 2 Base):\", non_instruct_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8k4wnoDQL5B",
        "outputId": "d88454bd-d1fd-4b9a-fc9d-051fd85d6eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not instruction-tuned output (Llama 2 Base): .\n",
            "Tell me how to train my dog to sit. I have a 10 month old puppy and I want to train him to sit. I have tried the treat method and the verbal command method. I have tried both and he just doesn't seem to get it. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and pushing him down. I have tried to get him to sit by putting my hand on his back and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruct_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "instruct_output = instruct_model(\"Tell me how to train my dog to sit\")\n",
        "print(\"Instruction-tuned output (Llama 2): \", instruct_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOD8uvP6QQ7s",
        "outputId": "2058aa70-2904-47a9-dcfd-7825f5e22277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction-tuned output (Llama 2):   on command.\n",
            "Training a dog to sit on command is a basic obedience command that can be achieved with patience, consistency, and positive reinforcement. Here's a step-by-step guide on how to train your dog to sit on command:\n",
            "\n",
            "1. Choose a quiet and distraction-free area: Find a quiet area with minimal distractions where your dog can focus on you.\n",
            "2. Have treats ready: Choose your dog's favorite treats and have them ready to use as rewards.\n",
            "3. Stand in front of your dog: Stand in front of your dog and hold a treat close to their nose.\n",
            "4. Move the treat up and back: Slowly move the treat up and back, towards your dog's tail, while saying \"sit\" in a calm and clear voice.\n",
            "5. Dog will sit: As you move the treat, your dog will naturally sit down to follow the treat. The moment their bottom touches the ground, say \"good sit\" and give them the treat.\n",
            "6. Repeat the process: Repeat steps 3-5 several times, so your dog starts to associate the command \"sit\" with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2hz5qUcdUPTU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}