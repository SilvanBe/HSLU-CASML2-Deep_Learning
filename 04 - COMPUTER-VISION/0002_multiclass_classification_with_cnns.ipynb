{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSuXUMIVmhgo"
      },
      "source": [
        "# Multiclass Classification with Convolutional Neural Networks\n",
        "Version 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJo_NK-nmqCf"
      },
      "source": [
        "(C) 2020 - Umberto Michelucci, Michela Sperti  \n",
        "(C) 2023 - Alessandro Motta\n",
        "\n",
        "This notebook is part of the book _Applied Deep Learning: a case based approach, **2nd edition**_ from APRESS by [U. Michelucci](mailto:umberto.michelucci@toelt.ai) and [M. Sperti](mailto:michela.sperti@toelt.ai)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31wfEV06mtro"
      },
      "source": [
        "The purpose of this notebook is to give a practical example (with a dataset taken from the real world) of a multiclass classification problem solved by means of a Convolutional Neural Network (CNN) architecture. It may be instructive to compare the results of this notebook with the ones of *Multiclass_classification_with_fully_connected_networks.ipynb* notebook, which solves the same problem, but with a simpler architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2wkdTiVmy1F"
      },
      "source": [
        "## Notebook Learning Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pqNL9dfm4Uj"
      },
      "source": [
        "At the end of the notebook you are going to know how to implement yourself a CNN architecture in Keras. Moreover, you will be able to to apply it to other image recognition problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG0PGsm0GFGe"
      },
      "source": [
        "## Dataset Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZu1AsdvGHEh"
      },
      "source": [
        "**Context**\n",
        "\n",
        "Fashion-MNIST is a dataset of Zalando's article images (consisting of a training set of 60000 examples and a test set of 10000 examples). Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
        "\n",
        "The original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\"\n",
        "Zalando seeks to replace the original MNIST dataset\n",
        "\n",
        "**Content**\n",
        "\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
        "\n",
        "To locate a pixel on the image, suppose that we have decomposed $x$ as $x = 28i + j$, where $i$ and $j$ are integers between 0 and 27. The pixel is located on row $i$ and column $j$ of a 28x28 matrix.\n",
        "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top.\n",
        "\n",
        "Each row of the dataset is a separate image. Column 1 is the class label.\n",
        "Remaining columns are pixel numbers (784 total). Each value is the darkness of the pixel (1 to 255).\n",
        "\n",
        "**Labels**\n",
        "\n",
        "Each training and test example is assigned to one of the following labels:\n",
        "- 0 T-shirt/top\n",
        "- 1 Trouser\n",
        "- 2 Pullover\n",
        "- 3 Dress\n",
        "- 4 Coat\n",
        "- 5 Sandal\n",
        "- 6 Shirt\n",
        "- 7 Sneaker\n",
        "- 8 Bag\n",
        "- 9 Ankle boot\n",
        "\n",
        "**Acknowledgements**\n",
        "\n",
        "Original dataset was downloaded from TensorFlow datasets catalog.\n",
        "\n",
        "**License**\n",
        "\n",
        "The MIT License (MIT) Copyright © [2017] Zalando SE, https://tech.zalando.com\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt0OZlORGtYM"
      },
      "source": [
        "## Libraries and Dataset Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4Fr75NjGvv1"
      },
      "source": [
        "This section contains the necessary libraries (such as tensorflow or pandas) you need to import to run the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crb9ktSmG1fV"
      },
      "source": [
        "# general libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# tensorflow libraries\n",
        "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKM7o9rBG1qw"
      },
      "source": [
        "The following cells are needed to **download** the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWipOu2rG2mx"
      },
      "source": [
        "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
        "labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "          'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSYd3iXOR3Oh"
      },
      "source": [
        "**Let's have a look at our data**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBD50AE2HwU_"
      },
      "source": [
        "print('Dimensions of the training dataset: ', trainX.shape)\n",
        "print('Dimensions of the test dataset: ', testX.shape)\n",
        "print('Dimensions of the training labels: ', trainY.shape)\n",
        "print('Dimensions of the test labels: ', testY.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2jKbxwcTrMb"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fMAObnUTyb5"
      },
      "source": [
        "We now one-hot encode the labels and change the images dimensions, to get easy to use data for later. To know more about one-hot encoding process see the [Further Readings](#fr) section or refer to the hands-on chapter of the book about feed-forward neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdQrfB_mZykL"
      },
      "source": [
        "labels_train = np.zeros((60000, 10))\n",
        "labels_train[np.arange(60000), trainY] = 1\n",
        "\n",
        "data_train = trainX.reshape(60000, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEAUvO8WZ0LO"
      },
      "source": [
        "labels_test = np.zeros((10000, 10))\n",
        "labels_test[np.arange(10000), testY] = 1\n",
        "\n",
        "data_test = testX.reshape(10000, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XejNsNYFZ0PV"
      },
      "source": [
        "print('Dimensions of the training dataset: ', data_train.shape)\n",
        "print('Dimensions of the test dataset: ', data_test.shape)\n",
        "print('Dimensions of the training labels: ', labels_train.shape)\n",
        "print('Dimensions of the test labels: ', labels_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Inspection"
      ],
      "metadata": {
        "id": "EPh7qs5Jf0HE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "rand_ids = np.random.permutation(len(data_train))[:5]\n",
        "for i, rand_id in enumerate(rand_ids):\n",
        "  plt.subplot(1, len(rand_ids), i+1)\n",
        "  plt.title(labels[trainY[rand_id]])\n",
        "  plt.imshow(data_train[rand_id], cmap='gray')\n",
        "  plt.gca().set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vGzERvvYf2B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIYqLZPea3GV"
      },
      "source": [
        "## Data Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWZqPIM4a5v0"
      },
      "source": [
        "Let's normalize the training data dividing by 255.0 to get the values between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1v6CCnaa76t"
      },
      "source": [
        "data_train_norm = np.array(data_train/255.0)\n",
        "data_test_norm = np.array(data_test/255.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IqAZrSVEO67"
      },
      "source": [
        "## Convolutional Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyYbDfqeEnBc"
      },
      "source": [
        "Let us try to build one such a network to give you a feeling of how the process would work and how the code looks like. We will not do any hyperparameter tuning or optimization to keep the section understandable.\n",
        "\n",
        "Our CNN will be made of the following layers:\n",
        "- **CONV1**: 6 filters 5 x 5, stride $s=1$\n",
        "- We then apply **ReLU** to the output of the previous layer\n",
        "- **POOL1** with a window 2 × 2, stride $s=2$\n",
        "- **CONV2**: 16 Filters 5 × 5, stride $s=1$\n",
        "- We then apply **ReLU** to the output of the previous layer\n",
        "- **POOL2** with a window 2 × 2, stride $s=2$\n",
        "- **Fully Connected Layer** with 128 neurons with activation function ReLU\n",
        "- **Fully Connected Layer** with 10 neurons for classification of the Zalando dataset\n",
        "- **Softmax** output neuron\n",
        "\n",
        "Softmax function here is needed since we one-hot encoded the labels. To have more details about this, see the [Further Readings](#fr) section of the notebook or refer to the hands-on chapter of the book about feed-forward neural networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the Model Architecture"
      ],
      "metadata": {
        "id": "VMeyhPmYleIX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBlU5_N2EJ6-"
      },
      "source": [
        "def build_model():\n",
        "  # create model\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(6, (5, 5), strides = (1, 1), activation = 'relu', input_shape = (28, 28, 1)))\n",
        "  model.add(layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "  model.add(layers.Conv2D(16, (5, 5), strides = (1, 1), activation = 'relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation = 'relu'))\n",
        "  model.add(layers.Dense(10, activation = 'softmax'))\n",
        "  # compile model\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['categorical_accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gdG4qqzI5nF"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymu43BtWI-5w"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYbShXCFN84J"
      },
      "source": [
        "We now train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model"
      ],
      "metadata": {
        "id": "os4cBnR6lijM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AwtbN9UJHkz"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(\n",
        "  data_train_norm, labels_train,\n",
        "  epochs = EPOCHS, verbose = 1,\n",
        "  batch_size = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82Mu5ohzProZ"
      },
      "source": [
        "And we used the trained model on the test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantitative and Qualitative Evaluation of the Model"
      ],
      "metadata": {
        "id": "v2bSeb03llDF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFcN93oZPyY-"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(data_test_norm, labels_test, verbose = 0)\n",
        "print('The accuracy on the test set is equal to: ', int(test_accuracy*100), '%.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "rand_ids = np.random.permutation(len(data_test))[:5]\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "for i, rand_id in enumerate(rand_ids):\n",
        "  actual_label = labels[testY[rand_id]]\n",
        "  predicted_label = np.expand_dims(data_test_norm[rand_id], axis=0)\n",
        "  predicted_label = labels[np.argmax(model.predict(predicted_label, verbose=False))]\n",
        "\n",
        "  plt.subplot(1, len(rand_ids), i+1)\n",
        "  plt.title(f\"Predicted: {predicted_label}\\nActual: {actual_label}\")\n",
        "  plt.imshow(data_test[rand_id], cmap='gray')\n",
        "  plt.gca().set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AEDHBzRLjPpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How robust is the CNN?\n",
        "\n",
        "Exercise: Pick an image that gets correctly classified by the CNN, then try to change the image such that it gets misclassified."
      ],
      "metadata": {
        "id": "qFAgkQrCkuq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corrupt_image(image):\n",
        "  # FILL IN HERE\n",
        "  return image\n",
        "\n",
        "sample_id = 0\n",
        "actual_label = labels[testY[sample_id]]\n",
        "\n",
        "# Predict label for sample image\n",
        "sample_image = data_test_norm[sample_id]\n",
        "predicted_label = np.expand_dims(sample_image, axis=0)\n",
        "predicted_label = labels[np.argmax(model.predict(predicted_label, verbose=False))]\n",
        "assert predicted_label == actual_label, \"Pick a sample that is correctly classified\"\n",
        "\n",
        "# Predict label for corrupted image\n",
        "corrupted_image = corrupt_image(sample_image)\n",
        "corrupted_label = np.expand_dims(corrupted_image, axis=0)\n",
        "corrupted_label = labels[np.argmax(model.predict(corrupted_label, verbose=False))]\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(predicted_label)\n",
        "plt.imshow(sample_image, cmap='gray', vmin=0, vmax=1)\n",
        "plt.gca().set_axis_off()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(corrupted_label)\n",
        "plt.imshow(corrupted_image, cmap='gray', vmin=0, vmax=1)\n",
        "plt.gca().set_axis_off()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kqG0ckPQl10-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What Filters were learned?"
      ],
      "metadata": {
        "id": "ldjqbffFqSZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: Get an impression\n",
        "\n",
        "- of the filters (convolutional kernels) that were learned during training, and\n",
        "- of how the input image is transformed by the CNN."
      ],
      "metadata": {
        "id": "tdYvLKu8lvSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_image = data_test_norm[0]\n",
        "\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.title('Input image')\n",
        "plt.imshow(sample_image, cmap='gray', vmin=0, vmax=1)\n",
        "plt.gca().set_axis_off()\n",
        "plt.show()\n",
        "\n",
        "model_up_to_first_conv = models.Sequential(model.layers[:1])\n",
        "model_up_to_second_conv = models.Sequential(model.layers[:3])\n",
        "\n",
        "for title, submodel in [('After first convolutional layer', model_up_to_first_conv),\n",
        "                        ('After second convolutional layer', model_up_to_second_conv)]:\n",
        "  features = submodel.predict(np.expand_dims(sample_image, axis=0), verbose=False)[0]\n",
        "  features = np.split(features, features.shape[2], axis=2)\n",
        "\n",
        "  print()\n",
        "  n_cols = 4\n",
        "  n_rows = int(np.ceil(len(features) / n_cols))\n",
        "  plt.figure(figsize=(8, n_rows * 2))\n",
        "  for i, feature in enumerate(features):\n",
        "    plt.subplot(n_rows, n_cols, i+1)\n",
        "    plt.imshow(feature, cmap='gray')\n",
        "    if i == 0: plt.title(title)\n",
        "    plt.gca().set_axis_off()\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "6I0caY3RqZ7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Adversarial Examples\n",
        "\n",
        "Here, we try to fool the convolutional neural network into misclassifying an image. Instead of using backpropagation to compute how to change the weights to reduce the loss, here we use backpropagation to compute **how to change the image to increase the loss**.\n",
        "\n",
        "Specifically, we use the \"Fast Gradient Sign Method\" from:\n",
        "\n",
        "Goodfellow, Shlens, and Szegedy (2014) arXiv  \n",
        "Explaining and Harnessing Adversarial Examples  \n",
        "https://arxiv.org/abs/1412.6572"
      ],
      "metadata": {
        "id": "RHsDeI0fga4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient_sign(model, image, label):\n",
        "  image = tf.convert_to_tensor(np.expand_dims(image, axis=0))\n",
        "  label = tf.convert_to_tensor(np.expand_dims(label, axis=0))\n",
        "\n",
        "  loss_function = losses.CategoricalCrossentropy()\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(image)\n",
        "    prediction = model(image)\n",
        "    loss = loss_function(label, prediction)\n",
        "\n",
        "  gradient = tape.gradient(loss, image)[0]\n",
        "  grad_sign = np.sign(gradient)\n",
        "  return grad_sign"
      ],
      "metadata": {
        "id": "jTAairJ-hv7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_id = 1\n",
        "sample_image = data_test_norm[sample_id]\n",
        "sample_label = labels_test[sample_id]\n",
        "\n",
        "# Compute the sign of the gradient of the loss with respect to the image\n",
        "grad_sign = compute_gradient_sign(model, sample_image, sample_label)\n",
        "\n",
        "# Perturb the original input image\n",
        "adversarial_perturbation = 0.1 * grad_sign\n",
        "adversarial_sample = sample_image + adversarial_perturbation\n",
        "\n",
        "plt.figure(figsize=(9, 3))\n",
        "\n",
        "for i, (image, title) in enumerate([\n",
        "    (sample_image, 'Original image'),\n",
        "    (adversarial_perturbation, 'Adversarial perturbation'),\n",
        "    (adversarial_sample, 'Adversarial sample')]):\n",
        "  prob = model.predict(np.expand_dims(image, axis=0), verbose=False)[0]\n",
        "  label = labels[np.argmax(prob)]\n",
        "  prob = np.max(prob)\n",
        "\n",
        "  plt.subplot(1, 3, i+1)\n",
        "  plt.imshow(image, cmap='gray', vmin=0, vmax=1)\n",
        "  plt.title(f\"{title}\\n{int(100 * prob):d}% {label}\")\n",
        "  plt.gca().set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nx298C-8lQtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning the Fashion Model on MNIST Digits\n",
        "\n",
        "In practice, you likely need much more complex convolutional neural networks (CNN) with many more parameters. At the same time, it is challenging to generate a labeled dataset with millions of samples.\n",
        "\n",
        "A common strategy in this situation is to \"fine-tune\" a larger CNN. This means: reusing the convolutional layers (sometimes called the \"backbone\") for feature extraction, but training a new, final fully-connected layer (sometimes called \"readout layer\") specifically for the problem at hand. Because the readout layer contains only few parameters compared to the entire model, you can get away with little training data.\n",
        "\n",
        "**Exercise:** Fine-tune the Fashion MNIST model on the original MNIST dataset that consists of hand-written digits. Try to find out how many training samples are needed to satisfactory performance of the fine-tuned model.\n",
        "\n",
        "**HINT:** If you have $N$ training samples, a batch size of $B$, and train for $E$ epochs, then the model parameters will be optimized over $N / B \\times E$ gradient steps. Thus, when reducing the number of training samples, you might have to increase the number of epochs for model parameters to reach an optimum."
      ],
      "metadata": {
        "id": "F6ZYOFGW5-nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the MNIST Dataset"
      ],
      "metadata": {
        "id": "DU8xeHmW97Qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "kWtIS3Ay6Ev6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing MNIST training data\n",
        "mnist_x_train = mnist_x_train.reshape(60000, 28, 28, 1)\n",
        "mnist_x_train = np.array(mnist_x_train / 255.0)\n",
        "\n",
        "mnist_labels_train = np.zeros((60000, 10))\n",
        "mnist_labels_train[np.arange(60000), mnist_y_train] = 1\n",
        "\n",
        "# Preparing MNIST test data\n",
        "mnist_x_test = mnist_x_test.reshape(10000, 28, 28, 1)\n",
        "mnist_x_test = np.array(mnist_x_test / 255.0)\n",
        "\n",
        "mnist_labels_test = np.zeros((10000, 10))\n",
        "mnist_labels_test[np.arange(10000), mnist_y_test] = 1"
      ],
      "metadata": {
        "id": "DHIUAbQr6QpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 3))\n",
        "rand_ids = np.random.permutation(len(mnist_x_train))[:5]\n",
        "for i, rand_id in enumerate(rand_ids):\n",
        "  plt.subplot(1, len(rand_ids), i+1)\n",
        "  plt.imshow(mnist_x_train[rand_id], cmap='gray', vmin=0, vmax=1)\n",
        "  plt.gca().set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "om9Ay0rp9_na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse convolutional layers from Fashion model\n",
        "mnist_model = models.Sequential(model.layers[:-1])\n",
        "\n",
        "# Do not (re)train convolutions from Fashion model\n",
        "for layer in mnist_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Add new dense (\"readout\") layers for MNIST model\n",
        "mnist_model.add(layers.Dense(10, activation = 'softmax'))\n",
        "mnist_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['categorical_accuracy'])\n",
        "mnist_model.summary()"
      ],
      "metadata": {
        "id": "AgkngFL47aA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "n_training_samples = 10_000\n",
        "\n",
        "np.random.seed(0)\n",
        "training_sample_ids = np.random.permutation(len(mnist_x_train))\n",
        "training_sample_ids = training_sample_ids[:n_training_samples]\n",
        "\n",
        "mnist_model.fit(\n",
        "  mnist_x_train[training_sample_ids],\n",
        "  mnist_labels_train[training_sample_ids],\n",
        "  epochs = EPOCHS,\n",
        "  batch_size = 100)"
      ],
      "metadata": {
        "id": "t51Hz-z89dZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, mnist_test_accuracy = mnist_model.evaluate(mnist_x_test, mnist_labels_test, verbose = 0)\n",
        "print('The accuracy on the test set is equal to: ', int(mnist_test_accuracy*100), '%.')"
      ],
      "metadata": {
        "id": "OUABizYb-oOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KpgX4W8nCd8"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J38NJG0nQRB"
      },
      "source": [
        "1. [*Easy Difficulty*] Try to build a multiclass classification model like the one we saw together in this notebook, but with a different dataset, the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/). To download the dataset from TensorFlow use the following lines of code:\n",
        "```\n",
        "from tensorflow import keras\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "```\n",
        "2. [*Medium Difficulty*] Try to change the network's parameters to see if you can get a higher accuracy. Change kernel size, stride, and padding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgjWwv5nHwH"
      },
      "source": [
        "## Further Readings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTbDJqUjnFvl"
      },
      "source": [
        "**Fashion-MNIST dataset**\n",
        "\n",
        "1. Xiao, Han, Kashif Rasul, and Roland Vollgraf. \"Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.\" arXiv preprint arXiv:1708.07747 (2017)\n",
        "\n",
        "**One-hot encoding, integer encoding, softmax function**\n",
        "\n",
        "1. https://deepai.org/machine-learning-glossary-and-terms/one-hot-encoding (what one-hot encoding means)\n",
        "2. https://towardsdatascience.com/softmax-activation-function-how-it-actually-works-d292d335bd78 (why we need to use softmax function and the difference between one-hot encoding and integer encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XLbzXl-lBTq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
